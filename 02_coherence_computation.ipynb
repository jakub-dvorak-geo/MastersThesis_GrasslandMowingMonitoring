{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6a083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyroSAR\n",
    "from pyroSAR.snap.auxil import parse_recipe, parse_node\n",
    "from pyroSAR.snap.auxil import gpt, groupbyWorkers\n",
    "\n",
    "from os.path import join, exists\n",
    "from os import makedirs\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coherence_gpt(in_slc_one, in_slc_two, dem_path, out_filename, out_graph_path, split_params, **kwargs):\n",
    "    \n",
    "    workflow = parse_recipe('blank')\n",
    "    \n",
    "    # 1st branch\n",
    "    read_one = parse_node('Read')\n",
    "    read_one.parameters['file'] = in_slc_one\n",
    "    workflow.insert_node(read_one)\n",
    "    \n",
    "    topsar_split_one = parse_node('TOPSAR-Split')\n",
    "    topsar_split_one.parameters['subswath'] = split_params['subswath']\n",
    "    topsar_split_one.parameters['firstBurstIndex'] = split_params['burst_first']\n",
    "    topsar_split_one.parameters['lastBurstIndex'] = split_params['burst_last']\n",
    "    workflow.insert_node(topsar_split_one, before=read_one.id)\n",
    "    \"\"\"\n",
    "    apply_orbit_one = parse_node('Apply-Orbit-File')\n",
    "    apply_orbit_one.parameters['orbitType'] = 'Sentinel Precise (Auto Download)'\n",
    "    apply_orbit_one.parameters['polyDegree'] = 3\n",
    "    # WARNING - the script currently ignores orbit file application if it is not found\n",
    "    apply_orbit_one.parameters['continueOnFail'] = 'true'\n",
    "    workflow.insert_node(apply_orbit_one, before=topsar_split_one.id)\n",
    "    \"\"\"\n",
    "    # 2nd branch\n",
    "    read_two = parse_node('Read')\n",
    "    read_two.parameters['file'] = in_slc_two\n",
    "    workflow.insert_node(read_two)\n",
    "    \n",
    "    topsar_split_two = parse_node('TOPSAR-Split')\n",
    "    topsar_split_two.parameters['subswath'] = split_params['subswath']\n",
    "    topsar_split_two.parameters['firstBurstIndex'] = split_params['burst_first']\n",
    "    topsar_split_two.parameters['lastBurstIndex'] = split_params['burst_last']\n",
    "    workflow.insert_node(topsar_split_two, before=read_two.id)\n",
    "    \"\"\"\n",
    "    apply_orbit_two = parse_node('Apply-Orbit-File')\n",
    "    apply_orbit_two.parameters['orbitType'] = 'Sentinel Precise (Auto Download)'\n",
    "    apply_orbit_two.parameters['polyDegree'] = 3\n",
    "    # WARNING - the script currently ignores orbit file application if it is not found\n",
    "    apply_orbit_two.parameters['continueOnFail'] = 'true'\n",
    "    workflow.insert_node(apply_orbit_two, before=topsar_split_two.id)\n",
    "    \"\"\"\n",
    "    # combined branch\n",
    "    back_geocoding = parse_node('Back-Geocoding')\n",
    "    back_geocoding.parameters['demName'] = 'External DEM'\n",
    "    back_geocoding.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    back_geocoding.parameters['externalDEMFile'] = dem_path\n",
    "    back_geocoding.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    back_geocoding.parameters['resamplingType'] = 'BILINEAR_INTERPOLATION'\n",
    "    back_geocoding.parameters['maskOutAreaWithoutElevation'] = 'false'\n",
    "    back_geocoding.parameters['outputRangeAzimuthOffset'] = 'false'\n",
    "    back_geocoding.parameters['outputDerampDemodPhase'] = 'false'\n",
    "    back_geocoding.parameters['disableReramp'] = 'false'\n",
    "    #workflow.insert_node(back_geocoding, before=[apply_orbit_one.id, apply_orbit_two.id])\n",
    "    workflow.insert_node(back_geocoding, before=[topsar_split_one.id, topsar_split_two.id])\n",
    "\n",
    "    coherence = parse_node('Coherence')\n",
    "    coherence.parameters['cohWinAz'] = 2\n",
    "    coherence.parameters['cohWinRg'] = 10\n",
    "    #coherence.parameters['substractFlatEarthPhase'] = 'false'\n",
    "    coherence.parameters['srpPolynomialDegree'] = 5\n",
    "    coherence.parameters['srpNumberPoints'] = 501\n",
    "    coherence.parameters['orbitDegree'] = 3\n",
    "    coherence.parameters['squarePixel'] = 'true'\n",
    "    coherence.parameters['subtractTopographicPhase'] = 'false'\n",
    "    coherence.parameters['demName'] = 'External DEM'\n",
    "    #coherence.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    coherence.parameters['externalDEMFile'] = dem_path\n",
    "    coherence.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    coherence.parameters['externalDEMApplyEGM'] = 'true'\n",
    "    coherence.parameters['tileExtensionPercent'] = 100\n",
    "    coherence.parameters['singleMaster'] = 'true'\n",
    "    workflow.insert_node(coherence, before=back_geocoding.id)\n",
    "\n",
    "    deburst = parse_node('TOPSAR-Deburst')\n",
    "    workflow.insert_node(deburst, before=coherence.id)\n",
    "\n",
    "    tc = parse_node('Terrain-Correction')\n",
    "    tc.parameters['demName'] = 'External DEM'\n",
    "    tc.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    tc.parameters['externalDEMFile'] = dem_path\n",
    "    tc.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    tc.parameters['externalDEMApplyEGM'] = 'true'\n",
    "\n",
    "    tc.parameters['imgResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    tc.parameters['pixelSpacingInMeter'] = 0.0\n",
    "    tc.parameters['pixelSpacingInDegree'] = 0.0\n",
    "    tc.parameters['mapProjection'] = '''GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\",\n",
    "        SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], \n",
    "        AUTHORITY[\"EPSG\",\"6326\"]], \n",
    "        PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], \n",
    "        UNIT[\"degree\", 0.017453292519943295], \n",
    "        AXIS[\"Geodetic longitude\", EAST], \n",
    "        AXIS[\"Geodetic latitude\", NORTH], \n",
    "        AUTHORITY[\"EPSG\",\"4326\"]]'''\n",
    "    # maybe? so everything is aligned\n",
    "    tc.parameters['alignToStandardGrid'] = 'true'\n",
    "    tc.parameters['standardGridOriginX'] = 0.0\n",
    "    tc.parameters['standardGridOriginY'] = 0.0\n",
    "    tc.parameters['nodataValueAtSea'] = 'false'\n",
    "    tc.parameters['saveDEM'] = 'false'\n",
    "    tc.parameters['saveLatLon'] = 'false'\n",
    "    tc.parameters['saveIncidenceAngleFromEllipsoid'] = 'false'\n",
    "    tc.parameters['saveLocalIncidenceAngle'] = 'false'\n",
    "    tc.parameters['saveProjectedLocalIncidenceAngle'] = 'false'\n",
    "    tc.parameters['saveSelectedSourceBand'] = 'true'\n",
    "    tc.parameters['saveLayoverShadowMask'] = 'false'\n",
    "    #tc.parameters['outputComplex'] = 'false'\n",
    "    tc.parameters['applyRadiometricNormalization'] = 'false'\n",
    "    tc.parameters['saveSigmaNought'] = 'false'\n",
    "    tc.parameters['saveGammaNought'] = 'false'\n",
    "    tc.parameters['saveBetaNought'] = 'false'\n",
    "    tc.parameters['incidenceAngleForSigma0'] = 'Use projected local incidence angle from DEM'\n",
    "    tc.parameters['incidenceAngleForGamma0'] = 'Use projected local incidence angle from DEM'\n",
    "    tc.parameters['auxFile'] = 'Latest Auxiliary File'\n",
    "    workflow.insert_node(tc, before=deburst.id)\n",
    "\n",
    "    write = parse_node('Write')\n",
    "    write.parameters['file'] = out_filename\n",
    "    write.parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "    workflow.insert_node(write, before=tc.id)\n",
    "\n",
    "    workflow.write(out_graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f92e71-5231-4106-835d-799111d61307",
   "metadata": {},
   "source": [
    "### Run processing in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458527f4-bd9e-48c0-86cf-86691dbcfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directiories used\n",
    "ROOT_DIR = 'd:\\\\studenti\\\\JD\\\\DP'\n",
    "\n",
    "dtm_path = join(ROOT_DIR, 'DTM\\\\DMR_4G_4326.tif')\n",
    "temp_dir = join(ROOT_DIR, 'temp')\n",
    "xmls_dir = join(temp_dir, 'snap_xmls')\n",
    "makedirs(xmls_dir) if not exists(xmls_dir) else print(f'{xmls_dir} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5bd69-46f3-4d3f-ba1d-b3743fb0f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of data directories to process and corresponding list of parameters to the TOPSAR_split function\n",
    "data_dir_list = (join(ROOT_DIR, 's1_download\\\\2021\\\\146'), )\n",
    "out_dir_list = (join(ROOT_DIR, 's1_coherence\\\\2021\\\\146'), )\n",
    "split_params_list = ({\n",
    "    'subswath': 'IW3',\n",
    "    'burst_first': 2,\n",
    "    'burst_last': 3}, )\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d723d-95c7-4508-bae1-190054d3d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_dir, out_dir, split_params in zip(data_dir_list, out_dir_list, split_params_list):\n",
    "    files_list = glob('S1*.zip', root_dir=data_dir)\n",
    "    files_list.sort(key=lambda x : x[17:25])\n",
    "    dates_list = (filename[17:25] for filename in files_list)\n",
    "    \n",
    "    for idx in range(len(files_list)-1):\n",
    "        date_1, date_2 = files_list[idx][17:25], files_list[idx+1][17:25]\n",
    "        print(f'Computing coherence between images from {date_1} and {date_2}')\n",
    "    \n",
    "        graph_path = join(xmls_dir, f'coherence_{date_1}_{date_2}.xml')\n",
    "        in_filepath_one = join(data_dir, files_list[idx])\n",
    "        in_filepath_two = join(data_dir, files_list[idx+1])\n",
    "        out_path = join(out_dir, f'coh_{date_1}_{date_2}')\n",
    "    \n",
    "        create_coherence_gpt(in_filepath_one, in_filepath_two, dtm_path, out_path, graph_path, split_params)\n",
    "        gpt(xmlfile=graph_path, tmpdir=temp_dir, groups=groupbyWorkers(graph_path, n=2))\n",
    "\n",
    "#rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638d28d-5cf7-4a95-bc48-00a15753669d",
   "metadata": {},
   "source": [
    "## Possibly no longer needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa6ac7-6a09-4d70-9617-dd302bb25bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_filepath = 'F:/datasets/NATUR_CUNI/DEM/DMR_4G_4326.tif'\n",
    "workflow_dir = 'C:/users/dd/documents/natur_cuni/_dp/code_git_repo/snap_scripts'\n",
    "DATA_DIR = 'F:/datasets/NATUR_CUNI/_dp_download/sentinel1/146'\n",
    "out_dir = 'F:/datasets/NATUR_CUNI/_dp_coherence/2021/146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba06589-7b81-4eed-af8e-ce5dcd4bc55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = glob('S1*.zip', root_dir=DATA_DIR)\n",
    "dates_list = [filename[17:25] for filename in files_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a41681-3119-41ee-85c4-aa9854f4d127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_list.sort(key=lambda x : x[17:25])\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fb0a0-28bf-4f07-8e9d-79d1f8224ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(files_list)-1):\n",
    "    date_1, date_2 = files_list[idx][17:25], files_list[idx+1][17:25]\n",
    "    print(f'Computing coherence between images from {date_1} and {date_2}')\n",
    "    \n",
    "    graph_path = join(workflow_dir, f'coherence_{date_1}_{date_2}.xml')\n",
    "    in_filepath_one = join(DATA_DIR, files_list[idx])\n",
    "    in_filepath_two = join(DATA_DIR, files_list[idx+1])\n",
    "    out_filepath = join(out_dir, f'coh_{date_1}_{date_2}')\n",
    "    \n",
    "    create_coherence_gpt(in_filepath_one, in_filepath_two, dem_filepath, out_filepath, graph_path)\n",
    "    gpt(graph_path, DATA_DIR, groups=groupbyWorkers(graph_path, n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88670c14-2878-473f-a5ae-6bc557b55f4d",
   "metadata": {},
   "source": [
    "### Show capture dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08242369-160f-4249-b905-4e003cfeb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list.sort()\n",
    "print(dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc692e20-f404-4571-9ce4-776061a009e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([datetime.strptime(i, '%Y%m%d') for i in dates_list], len(dates_list)*[0], '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7122a-13c5-439e-8279-9f614859bc92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
