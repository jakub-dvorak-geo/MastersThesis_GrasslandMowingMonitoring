{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6a083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyroSAR\n",
    "from pyroSAR.snap.auxil import parse_recipe, parse_node\n",
    "from pyroSAR.snap.auxil import gpt, groupbyWorkers\n",
    "\n",
    "from os.path import join, exists, basename\n",
    "from os import makedirs\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac15ec-a324-476b-a743-aa6aae6cafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_gpt(out_gpt, in_slc, out_slc, subswath, bursts):\n",
    "\n",
    "    workflow = parse_recipe('blank')\n",
    "\n",
    "    read = parse_node('Read')\n",
    "    read.parameters['file'] = in_slc\n",
    "    workflow.insert_node(read)\n",
    "    \n",
    "    topsar_split = parse_node('TOPSAR-Split')\n",
    "    topsar_split.parameters['subswath'] = subswath\n",
    "    topsar_split.parameters['firstBurstIndex'] = bursts[0]\n",
    "    topsar_split.parameters['lastBurstIndex'] = bursts[1]\n",
    "    workflow.insert_node(topsar_split, before=read.id)\n",
    "    \n",
    "    apply_orbit = parse_node('Apply-Orbit-File')\n",
    "    apply_orbit.parameters['orbitType'] = 'Sentinel Precise (Auto Download)'\n",
    "    apply_orbit.parameters['polyDegree'] = 3\n",
    "    apply_orbit.parameters['continueOnFail'] = 'false'\n",
    "    workflow.insert_node(apply_orbit, before=topsar_split.id)\n",
    "    \n",
    "    write = parse_node('Write')\n",
    "    write.parameters['file'] = out_slc\n",
    "    write.parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "    workflow.insert_node(write, before=apply_orbit.id)\n",
    "\n",
    "    workflow.write(out_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coherence_gpt(out_gpt, in_slc_0, in_slc_one, in_slc_two, dem_path, out_filename, subswath, bursts, **kwargs):\n",
    "    \n",
    "    workflow = parse_recipe('blank')\n",
    "    \n",
    "    # 0th branch - Read common master\n",
    "    read_0 = parse_node('Read')\n",
    "    read_0.parameters['file'] = in_slc_0\n",
    "    workflow.insert_node(read_0)\n",
    "    \n",
    "    # 1st branch - preprocess first slc\n",
    "    read_one = parse_node('Read')\n",
    "    read_one.parameters['file'] = in_slc_one\n",
    "    workflow.insert_node(read_one)\n",
    "    \n",
    "    topsar_split_one = parse_node('TOPSAR-Split')\n",
    "    topsar_split_one.parameters['subswath'] = subswath\n",
    "    topsar_split_one.parameters['firstBurstIndex'] = bursts[0][0]\n",
    "    topsar_split_one.parameters['lastBurstIndex'] = bursts[0][1]\n",
    "    workflow.insert_node(topsar_split_one, before=read_one.id)\n",
    "    \n",
    "    apply_orbit_one = parse_node('Apply-Orbit-File')\n",
    "    apply_orbit_one.parameters['orbitType'] = 'Sentinel Precise (Auto Download)'\n",
    "    apply_orbit_one.parameters['polyDegree'] = 3\n",
    "    apply_orbit_one.parameters['continueOnFail'] = 'false'\n",
    "    workflow.insert_node(apply_orbit_one, before=topsar_split_one.id)\n",
    "    \n",
    "    # 2nd branch - preprocess second slc\n",
    "    read_two = parse_node('Read')\n",
    "    read_two.parameters['file'] = in_slc_two\n",
    "    workflow.insert_node(read_two)\n",
    "    \n",
    "    topsar_split_two = parse_node('TOPSAR-Split')\n",
    "    topsar_split_two.parameters['subswath'] = subswath\n",
    "    topsar_split_two.parameters['firstBurstIndex'] = bursts[0][0]\n",
    "    topsar_split_two.parameters['lastBurstIndex'] = bursts[0][1]\n",
    "    workflow.insert_node(topsar_split_two, before=read_two.id)\n",
    "    \n",
    "    apply_orbit_two = parse_node('Apply-Orbit-File')\n",
    "    apply_orbit_two.parameters['orbitType'] = 'Sentinel Precise (Auto Download)'\n",
    "    apply_orbit_two.parameters['polyDegree'] = 3\n",
    "    apply_orbit_two.parameters['continueOnFail'] = 'false'\n",
    "    workflow.insert_node(apply_orbit_two, before=topsar_split_two.id)\n",
    "    \n",
    "    # combined branch\n",
    "    # coregister preprocessed slcs from all three branches\n",
    "    back_geocoding = parse_node('Back-Geocoding')\n",
    "    back_geocoding.parameters['demName'] = 'External DEM'\n",
    "    back_geocoding.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    back_geocoding.parameters['externalDEMFile'] = dem_path\n",
    "    back_geocoding.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    back_geocoding.parameters['resamplingType'] = 'BILINEAR_INTERPOLATION'\n",
    "    back_geocoding.parameters['maskOutAreaWithoutElevation'] = 'false'\n",
    "    back_geocoding.parameters['outputRangeAzimuthOffset'] = 'false'\n",
    "    back_geocoding.parameters['outputDerampDemodPhase'] = 'false'\n",
    "    back_geocoding.parameters['disableReramp'] = 'false'\n",
    "    workflow.insert_node(back_geocoding, before=[read_0.id, apply_orbit_one.id, apply_orbit_two.id])\n",
    "\n",
    "    # select only bands from the two subsequent slave images\n",
    "    band_select = parse_node('BandSelect')\n",
    "    band_select.parameters['bandNamePattern'] = '.*slv.*'\n",
    "    workflow.insert_node(band_select, before=back_geocoding.id)\n",
    "    \n",
    "    # estimate coherence\n",
    "    coherence = parse_node('Coherence')\n",
    "    coherence.parameters['cohWinAz'] = 2\n",
    "    coherence.parameters['cohWinRg'] = 10\n",
    "    #coherence.parameters['substractFlatEarthPhase'] = 'false'\n",
    "    coherence.parameters['srpPolynomialDegree'] = 5\n",
    "    coherence.parameters['srpNumberPoints'] = 501\n",
    "    coherence.parameters['orbitDegree'] = 3\n",
    "    coherence.parameters['squarePixel'] = 'true'\n",
    "    coherence.parameters['subtractTopographicPhase'] = 'false'\n",
    "    coherence.parameters['demName'] = 'External DEM'\n",
    "    #coherence.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    coherence.parameters['externalDEMFile'] = dem_path\n",
    "    coherence.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    coherence.parameters['externalDEMApplyEGM'] = 'true'\n",
    "    coherence.parameters['tileExtensionPercent'] = 100\n",
    "    coherence.parameters['singleMaster'] = 'true'\n",
    "    workflow.insert_node(coherence, before=band_select.id)\n",
    "\n",
    "    deburst = parse_node('TOPSAR-Deburst')\n",
    "    workflow.insert_node(deburst, before=coherence.id)\n",
    "\n",
    "    tc = parse_node('Terrain-Correction')\n",
    "    tc.parameters['demName'] = 'External DEM'\n",
    "    tc.parameters['demResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    tc.parameters['externalDEMFile'] = dem_path\n",
    "    tc.parameters['externalDEMNoDataValue'] = 0.0\n",
    "    tc.parameters['externalDEMApplyEGM'] = 'true'\n",
    "\n",
    "    tc.parameters['imgResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "    tc.parameters['pixelSpacingInMeter'] = 0.0\n",
    "    tc.parameters['pixelSpacingInDegree'] = 0.0\n",
    "    tc.parameters['mapProjection'] = '''GEOGCS[\"WGS 84\", DATUM[\"World Geodetic System 1984\",\n",
    "        SPHEROID[\"WGS 84\", 6378137.0, 298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], \n",
    "        AUTHORITY[\"EPSG\",\"6326\"]], \n",
    "        PRIMEM[\"Greenwich\", 0.0, AUTHORITY[\"EPSG\",\"8901\"]], \n",
    "        UNIT[\"degree\", 0.017453292519943295], \n",
    "        AXIS[\"Geodetic longitude\", EAST], \n",
    "        AXIS[\"Geodetic latitude\", NORTH], \n",
    "        AUTHORITY[\"EPSG\",\"4326\"]]'''\n",
    "    # maybe? so everything is aligned\n",
    "    tc.parameters['alignToStandardGrid'] = 'true'\n",
    "    tc.parameters['standardGridOriginX'] = 0.0\n",
    "    tc.parameters['standardGridOriginY'] = 0.0\n",
    "    tc.parameters['nodataValueAtSea'] = 'false'\n",
    "    tc.parameters['saveDEM'] = 'false'\n",
    "    tc.parameters['saveLatLon'] = 'false'\n",
    "    tc.parameters['saveIncidenceAngleFromEllipsoid'] = 'false'\n",
    "    tc.parameters['saveLocalIncidenceAngle'] = 'false'\n",
    "    tc.parameters['saveProjectedLocalIncidenceAngle'] = 'false'\n",
    "    tc.parameters['saveSelectedSourceBand'] = 'true'\n",
    "    tc.parameters['saveLayoverShadowMask'] = 'false'\n",
    "    #tc.parameters['outputComplex'] = 'false'\n",
    "    tc.parameters['applyRadiometricNormalization'] = 'false'\n",
    "    tc.parameters['saveSigmaNought'] = 'false'\n",
    "    tc.parameters['saveGammaNought'] = 'false'\n",
    "    tc.parameters['saveBetaNought'] = 'false'\n",
    "    tc.parameters['incidenceAngleForSigma0'] = 'Use projected local incidence angle from DEM'\n",
    "    tc.parameters['incidenceAngleForGamma0'] = 'Use projected local incidence angle from DEM'\n",
    "    tc.parameters['auxFile'] = 'Latest Auxiliary File'\n",
    "    workflow.insert_node(tc, before=deburst.id)\n",
    "\n",
    "    write = parse_node('Write')\n",
    "    write.parameters['file'] = out_filename\n",
    "    write.parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "    workflow.insert_node(write, before=tc.id)\n",
    "\n",
    "    workflow.write(out_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f92e71-5231-4106-835d-799111d61307",
   "metadata": {},
   "source": [
    "### Run processing in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458527f4-bd9e-48c0-86cf-86691dbcfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directiories used\n",
    "ROOT_DIR = '/media/sf_JD/DP'\n",
    "\n",
    "dtm_path = join(ROOT_DIR, 'DTM/DMR_4G_4326.tif')\n",
    "temp_dir = join(ROOT_DIR, 'temp')\n",
    "xmls_dir = join(temp_dir, 'snap_xmls')\n",
    "makedirs(xmls_dir) if not exists(xmls_dir) else print(f'{xmls_dir} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7122a-13c5-439e-8279-9f614859bc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## old, did not wortk for orbits 22 and 95 - the burst indices are not constant accross the whole year\n",
    "topsar_split_params = {\n",
    "    22: {\n",
    "        'subswath': 'IW2',\n",
    "        'burst_first': 1,\n",
    "        'burst_last': 2},\n",
    "    73: {\n",
    "        'subswath': 'IW1',\n",
    "        'burst_first': 1,\n",
    "        'burst_last': 2},\n",
    "    95: {\n",
    "        'subswath': 'IW1',\n",
    "        'burst_first': 1,\n",
    "        'burst_last': 2},\n",
    "    146: {\n",
    "        'subswath': 'IW3',\n",
    "        'burst_first': 2,\n",
    "        'burst_last': 3},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897ea79-a8a0-4814-9382-dfd2ec916f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "subswaths = {\n",
    "    22: 'IW2',\n",
    "    73: 'IW1',\n",
    "    95: 'IW1',\n",
    "    146:'IW3'\n",
    "}\n",
    "#### Suitable bursts for individual products\n",
    "bursts = {\n",
    "    22: [\n",
    "        [6,7], [1,2], [6,7], [1,2], [6,7], [1,2], [6,7], [1,2], [1,2], [1,2],\n",
    "        [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2],\n",
    "        [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2]\n",
    "        ],\n",
    "    73: [[1,2]] * 30,\n",
    "    95: [\n",
    "        [1,2], [1,2], [5,6], [1,2], [5,6], [1,2], [5,6], [1,2], [1,2], [1,2],\n",
    "        [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2],\n",
    "        [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2], [1,2]\n",
    "        ],\n",
    "    146: [[2,3]] * 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5bd69-46f3-4d3f-ba1d-b3743fb0f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of data directories to process and corresponding list of parameters to the TOPSAR_split function\n",
    "years = (2021,)\n",
    "relative_orbs = (22, 73, 95, 146)\n",
    "\n",
    "# automate list creation based on years and ROs\n",
    "data_dir_list, out_dir_list, subswaths_list, bursts_list = [], [], [], []\n",
    "for year in years:\n",
    "    for relative_orb in relative_orbs:\n",
    "        data_dir_list.append(f'{ROOT_DIR}/s1_download/{year}/{relative_orb}')\n",
    "        out_dir_list.append(f'{ROOT_DIR}/s1_coherence/{year}/{relative_orb}')\n",
    "        subswaths_list.append(subswaths[relative_orb])\n",
    "        bursts_list.append(bursts[relative_orb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d723d-95c7-4508-bae1-190054d3d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_a = perf_counter()\n",
    "\n",
    "for data_dir, out_dir, subswath, bursts in zip(data_dir_list, out_dir_list, subswaths_list, bursts_list):\n",
    "    \n",
    "    files_list = glob('S1*.zip', root_dir=data_dir)\n",
    "    files_list.sort(key=lambda x : x[17:25])\n",
    "    dates_list = (filename[17:25] for filename in files_list)\n",
    "    print(f'Working on datasets in folder {data_dir}')\n",
    "\n",
    "    # preprocess master slc\n",
    "    master_in = join(data_dir, files_list[0])\n",
    "    master_gpt = join(xmls_dir, f'master_{basename(data_dir)}.xml')\n",
    "    master_preprocessed = join(temp_dir, f'master_{basename(data_dir)}')\n",
    "    create_master_gpt(master_gpt, master_in, master_preprocessed, subswath, bursts[0])\n",
    "    gpt(xmlfile=master_gpt, tmpdir=temp_dir)\n",
    "    print('Preprocessed common master image for coregistration.')\n",
    "    \n",
    "    for idx in range(len(files_list)-1):\n",
    "        time_aa = perf_counter()\n",
    "        date_1, date_2 = files_list[idx][17:25], files_list[idx+1][17:25]\n",
    "        print(f'Computing coherence between images from {date_1} and {date_2}')\n",
    "        \n",
    "        # check if the time differnece between computtaions is not too small\n",
    "        diff = int(str(datetime.strptime(date_2, \"%Y%m%d\") - datetime.strptime(date_1, \"%Y%m%d\")).split()[0])\n",
    "        if diff < 6:\n",
    "            warnings.warn(f'Computing coherence between observations only {diff} days apart. Is this correct?')\n",
    "    \n",
    "        graph_path = join(xmls_dir, f'coherence_{date_1}_{date_2}.xml')\n",
    "        in_filepath_one = join(data_dir, files_list[idx])\n",
    "        in_filepath_two = join(data_dir, files_list[idx+1])\n",
    "        out_path = join(out_dir, f'coh_{date_1}_{date_2}')\n",
    "    \n",
    "        create_coherence_gpt(graph_path, in_master, in_filepath_one, in_filepath_two, dtm_path, out_path, subswath, [bursts[idx], bursts[idx+1]])\n",
    "        gpt(xmlfile=graph_path, tmpdir=temp_dir, groups=groupbyWorkers(graph_path, n=2))\n",
    "\n",
    "        print(f'Done in {(perf_counter() - time_aa)/60:.2f} minutes')\n",
    "\n",
    "rmtree(temp_dir)\n",
    "print(f'Finished computing all coherences in {(perf_counter()-time_a)/3600:.2f} hours.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6b5f0-9a7d-4d21-829a-a279eea942f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with time diff to warn about coherences that are not far enough apart\n",
    "a, b = '20210403', '20210409'\n",
    "diff = int(str(datetime.strptime(b, \"%Y%m%d\") - datetime.strptime(a, \"%Y%m%d\")).split()[0])\n",
    "if diff > 6:\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1751c3-ce7b-47a4-95ee-9f11d9efb4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
